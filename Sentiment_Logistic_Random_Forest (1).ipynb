{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis using ML\n",
        "\n",
        "\n",
        "Reference Links:\n",
        "\n",
        "https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools"
      ],
      "metadata": {
        "id": "5iepNfAiWnPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yP9Q-fP_7Tq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sentiment_df = pd.read_csv(\"sentiment_dataset.csv\")\n",
        "sentiment_df.head()\n",
        "\n",
        "sentiment_df.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA - Sentiment Dataset"
      ],
      "metadata": {
        "id": "X9le-onrPBSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentiment_df.head()\n",
        "# print(sentiment_df.tail())\n",
        "print('\\n=============================================================\\n')\n",
        "\n",
        "# print(sentiment_df.info())\n",
        "\n",
        "print('### Numerical features ###','\\n')\n",
        "print(sentiment_df.describe(exclude=['O']))\n",
        "\n",
        "print('\\n=============================================================\\n')\n",
        "# print(sentiment_df['Sentiments'].value_counts())\n",
        "\n",
        "print(\"Number of duplicates: \" + str(sentiment_df.duplicated().sum()))\n",
        "# sentiment_df.drop_duplicates(inplace=True)\n",
        "\n",
        "print('\\n=============================================================\\n')\n",
        "\n",
        "# print(sentiment_df.isnull().sum())\n",
        "\n",
        "# # df.dropna(inplace=True)  # Drop rows with missing values\n",
        "# # Or\n",
        "# # df.fillna(<< write the value >>, inplace=True)  # Fill missing values with a specific value\n",
        "\n",
        "print('\\n=============================================================\\n')\n",
        "\n",
        "# sentiment_df.dtypes\n",
        "\n",
        "print('\\n=============================================================\\n')\n",
        "\n",
        "# # Creating New column with actual labels...\n",
        "# sentiment_df['Labels'] = 'Negative'\n",
        "# sentiment_df.loc[sentiment_df['Sentiments'], 'Labels'] = 'Positive'\n",
        "\n",
        "print('\\n=============================================================\\n')\n",
        "\n",
        "# New column to store word counts from Reviews column\n",
        "sentiment_df['Word_Count'] = sentiment_df['Review'].str.split().str.len()\n",
        "\n",
        "# # Define a function to count words in a review\n",
        "# def count_words(review):\n",
        "#     return len(review.split())\n",
        "\n",
        "# # Apply the function to each review in the 'Review' column and create a new column 'Word_Count'\n",
        "# df['Word_Count'] = df['Review'].apply(count_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "X2nD2ps2PAu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "Im1u_uHmXWk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "reviews = sentiment_df['Review']\n",
        "sentiments = sentiment_df['Sentiment']\n",
        "\n",
        "# You can adjust max_features as needed\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "text_data = tfidf_vectorizer.fit_transform(reviews)\n",
        "\n",
        "# splitting X and y into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_data, sentiments,\n",
        "                                       test_size=0.2,\n",
        "                                       random_state=17)"
      ],
      "metadata": {
        "id": "JrlzWtPGBQLG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Logistic Regression Classifier"
      ],
      "metadata": {
        "id": "cvF_yauuCLKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create logistic regression object\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Step 5: Model Training\n",
        "# train the model using the training sets\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation\n",
        "# making predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# comparing actual response values (y_test)\n",
        "# with predicted response values (y_pred)\n",
        "print(\"Logistic Regression model accuracy(in %):\", accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "# test review\n",
        "new_review = \"This is a new review that needs to be classified good movie.\"\n",
        "\n",
        "# Preprocess the new string using the same TF-IDF vectorizer\n",
        "new_review_features = tfidf_vectorizer.transform([new_review])\n",
        "\n",
        "# Predict the target label for the new string using the trained model\n",
        "predicted_label = model.predict(new_review_features)\n",
        "\n",
        "# Print the predicted label\n",
        "print(\"Predicted Label:\", \"Positive Sentiment\" if predicted_label[0] else \"Negative Sentiment\" )"
      ],
      "metadata": {
        "id": "kyZaqKevAF7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Random Forest Classifier"
      ],
      "metadata": {
        "id": "gdgoDfBrCR8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Step 5: Model Training\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy (Random Forest):\", accuracy_rf)\n",
        "\n",
        "new_review = \"This is a new review that needs to be classified good movie.\"\n",
        "# Preprocess the new string using the same TF-IDF vectorizer\n",
        "new_review_features = tfidf_vectorizer.transform([new_review])\n",
        "\n",
        "# Testing with a new string\n",
        "predicted_label_rf = rf_model.predict(new_review_features)\n",
        "print(\"Predicted Label (Random Forest):\", predicted_label_rf[0])\n"
      ],
      "metadata": {
        "id": "CnKh23g8AF4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ltdjYD9YV3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}